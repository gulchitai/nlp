{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2. Распознавание именованных сущностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во втором практическом задании мы будем решать задачу распознавания именованных сущностей. Будем различать три вида сущностей:\n",
    "- Фамилия, имя и отчство,\n",
    "- Названия городов,\n",
    "- Наименование контрагента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/2_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные. Данные представляют собой те же обращения пользователей, которые мы использовали в первом практическом задании, только теперь мы будем анализировать каждое слово обращения, а не все обращение целиком:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"ner_data_with_flowers.xlsx\")\n",
    "df[\"words\"] = df[\"words\"].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поля таблицы имеют три возможных значения:\n",
    "- $O$ - слово не является именованной сущностью\n",
    "- $н$ - начало именованной сущности\n",
    "- $п$ - продолжение именованной сущности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим примеры каждой именованной сущности:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Контрагент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Контрагент\"] != \"О\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Фамилия, имя и отчество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ФИО\"] != \"О\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Город:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Город\"] != \"О\"][:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращения разделеены вспомогательным символом \"----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[8:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это позволяет нам добавить информацию о номере обращения, слово из которого рассматривается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sent_number\"] = (df[\"words\"] == \"---\").astype(int).cumsum()\n",
    "df[8:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом нам необходимо преобразовать данные к виду, в котором они будут использоваться моделями (как и в первом практическом задании). Как видно, данные уже приведены к нижнему регистру и из них удалены знаки препинания. Так что в предобрабока будет включать в себя лишь приведение слов к нормальной форме путем лемматизации. Как и раньше, предпочтителен подход, при котором мы сперва лемматизируем все уникальные слова и только потом производим замены слов на их лемматизированные аналоги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "lemmatizer = MorphAnalyzer()\n",
    "to_normal_form = { word : lemmatizer.normal_forms(word) for word in df[\"words\"].unique() }\n",
    "df[\"words\"] = df[\"words\"].apply(lambda x : to_normal_form[x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать следующие методы распознавания именованных сущностей:\n",
    "- Неструктурированные методы\n",
    "    - Базовый подход, который будет заключаться в запоминании меток всех слов, которые встрчались в обучающем множестве\n",
    "    - Стадартандартные методы машинного обучения ($RandomForest$ и $LogisticRegression$)\n",
    "- Структурированные методы  \n",
    "    - Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве точности уже неинформативно использовать метрику $accuarcy$, поскольку выборка несбалансирована (мы можем получать высокую точность, предсказывая константную метку $O$, но это плохое предсказание). Поэтому в качестве метрики мы будем использовать три другие величины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть мы решаем бинарную задачу с метками $0$ и $1$. Рассмотрим следующие метрики:\n",
    "- **Precision (точность)** - это часть правильно размеченных объектов среди объектов с истиной меткой $1$\n",
    "- **Recall (полноста)** - это часть правильно размеченных объектов среди объектов с предсказанной меткой $1$\n",
    "- **F1 мера** - метрика, объединяющая **Precision** и **Recall** по следующему правилу:\n",
    "$$\n",
    "F_1 = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача моделей: получить высокую точность по каждой метрике для каждой из меток: $н$ и $п$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неструктурированные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с неструктурированных методов. Первоначально необходимо разбить слова всех обращений на обучающую и отложенную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df, test_size=0.2)\n",
    "print(\"===== полученные размерности =====\")\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_dev.shape:\", df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем приступить к реализации методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовый подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый подход заключается просто в запоминании тегов для все слов из тренировочного множества. Более подробно:\n",
    "- Для каждого уникального слова храним словарь, в котором записываем, сколько раз в тренировочном множестве встречались метки $О$, $н$ и $п$\n",
    "- Запоминаем самую частотную метку для каждого слова\n",
    "- Во время тестирования для каждогослова выдаем самую частотную метку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем класс, который будет обучаться и производить предсказания описанным выше способом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "class BasicModel(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        words = Series(X).unique().tolist()\n",
    "        self.vocabulary = {word : {\"О\" : 0, \"н\" : 0, \"п\" : 0} for word in words}\n",
    "        for word, entity in zip(X, y):\n",
    "            self.vocabulary[word][entity] += 1\n",
    "\n",
    "        self.memory = {}\n",
    "        for key, dictionary in self.vocabulary.items():\n",
    "            self.memory[key] = max(dictionary, key=dictionary.get)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "\n",
    "        return [self.memory.get(x, 'О') for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим реализованную модель и посмотрим на ее точность на отложенной выборке для каждой именованной сущности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_train = df_train[\"words\"].values.tolist()\n",
    "X_dev = df_dev[\"words\"].values.tolist()\n",
    "for name in [\"Контрагент\", \"Город\", \"ФИО\"]:\n",
    "    y_train = df_train[name].values.tolist()\n",
    "    y_dev = df_dev[name].values.tolist()\n",
    "    basic_model = BasicModel()\n",
    "    basic_model.fit(X_train, y_train)\n",
    "    print(\"=====\", name, \"=====\")\n",
    "    print(\"precision_score (начало сущности):\", precision_score(basic_model.predict(X_dev), y_dev, average=None)[1])\n",
    "    print(\"precision_score (продолжение сущности):\", precision_score(basic_model.predict(X_dev), y_dev, average=None)[2])\n",
    "    print(\"recall_score (начало сущности):\", recall_score(basic_model.predict(X_dev), y_dev, average=None)[1])\n",
    "    print(\"recall_score (продолжение сущности):\", recall_score(basic_model.predict(X_dev), y_dev, average=None)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что мы получили достаточнос хорошие результаты несмотря на несбалансированность выборки. Однако, такой подход может не сработать в других задачах, когда именованные сущности имеют более сложную структуру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стандартные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем использовать стандартные методы машинного обученя, нам необходимо каждому объекту из выборки (в нашем случае объекты - это слова) сопоставить признаковое описание. Каждому слову будем сопоставлять следующую информацию:\n",
    "- длину слова\n",
    "- является ли слово числом\n",
    "- содержит ли слово символы, отличные от букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(word):\n",
    "    \n",
    "    return np.array([len(word), word.isdigit(), word.isalpha()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем обучающую и отложенную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [feature_map(w) for w in df_train[\"words\"].values.tolist()]\n",
    "X_dev = [feature_map(w) for w in df_dev[\"words\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем применить стандартные модели. Начем со случайного леса и посмотрим на результат его работы для каждой именованной сущности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for name in [\"Контрагент\", \"Город\", \"ФИО\"]:\n",
    "    y_train = df_train[name].values.tolist()\n",
    "    y_dev = df_dev[name].values.tolist()\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_dev)\n",
    "    print(\"=====\", name, \"=====\")\n",
    "    print(\"precision_score (начало сущности):\", precision_score(prediction, y_dev, average=None)[1])\n",
    "    print(\"precision_score (продолжение сущности):\", precision_score(prediction, y_dev, average=None)[2])\n",
    "    print(\"recall_score (начало сущности):\", recall_score(prediction, y_dev, average=None)[1])\n",
    "    print(\"recall_score (продолжение сущности):\", recall_score(prediction, y_dev, average=None)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что за счет несбалансированности случайный лес обучился выдавать метку $O$ на каждом обращении для каждой сущности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 1\n",
    "**Задание:** \n",
    "- Обучите случайный лес так, чтобы модель перестала прогнозировать константную метку $O$\n",
    "- Используйте логистическую регрессию для увеличения значений метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Можете использовать следующие способы улучшения результата\n",
    "- Поскольку выборка является несбалансированной, модель склоняется к предсказанию метки $О$. Чтобы усилить влияние остальных меток при обучении, можно использовать параметр $class\\_weight$ при обучении. Например, можно использовать $class\\_weight$={$О$ : 1, $н$ : 10, $п$ : 10}, что будет означать, что мы хотим по 10 раз дублировать объекты, метки которых равны $н$ или $п$.\n",
    "- Попробуйте улучшить признаковое описание слов (функция $feature\\_map$). Например, задать условия на окончания слов или на количество гласных и согласных букв в слове."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучите случайный лес с измененными параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Начало кода\n",
    "\n",
    "#Конец кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте логистическую регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Начало кода\n",
    "\n",
    "#Конец кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(lr_prediction)) > 1 and len(set(rf_prediction)) > 1\n",
    "print(\"Проверка пройдена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Структурированные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы начинаем использовать модель, учитывающую порядок слов в предложении, так что старый подход, когда мы анализировали данные по словам и разбивали выборку на обучающую и отложенную не зависимо от их расположения в тексте, уже не подходит. Для каждого типа сущности будем использовать следующее представление данных:\n",
    "- Разобьем все слова на предложения (учитывая поле $sent\\_number$)\n",
    "- Каждое предложение представим списком пар $(word, entity)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\"ФИО\", \"Город\", \"Контрагент\"]:\n",
    "    get_pair_func = lambda s: [(word, entity) for word, entity in zip(s[\"words\"].values.tolist(),\n",
    "                                                                      s[name].values.tolist())]\n",
    "    grouped_words = df.groupby(\"sent_number\").apply(get_pair_func)\n",
    "    sentences[name] = [sentence for sentence in grouped_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[\"ФИО\"][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого типа сущности разобьем полученные представления на тренировочную и отложенную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences = {}\n",
    "dev_sentences = {}\n",
    "for name in [\"ФИО\", \"Город\", \"Контрагент\"]:\n",
    "    train_sentences[name], dev_sentences[name] = train_test_split(sentences[name], test_size=0.2)\n",
    "len(train_sentences[name]), len(dev_sentences[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можм приступить к применению модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reccurent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем применение рекурентной нейронной сети применительн ок задаче выделеения сущностей. В прошлом практическом задании мы классифицировали документы и использовали сеть типа $Many-to-one$, когда мы проходили по всем словам в обращении и использовали только последюю активацию:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/2_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас же мы должны сопоставить метку каждому слову в обращении, так что актуальна схема $Many-to-many$, когда количество входов нейронной сети совпадает с количеством выходов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/2_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим сеть к распознаванию имени, фамилии и отчества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ФИО\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и раньше, нам необходимо токенизировать обращения и зафиксировать длину обращений. Теперь метки сопоставляются каждом услову, так что их тоже необходимо сделать одинаковой длины. Напишем функции для преобразования обращений и меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "words = list(set(df[\"words\"].values))\n",
    "tags = list(set(df[name].values))\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {\"О\" : 0, \"н\" : 1, \"п\" : 2}\n",
    "\n",
    "def sentences2X(sentences):\n",
    "    X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "    X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\",value=len(words) - 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def sentences2y(sentences):\n",
    "    y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "    y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx['О'])\n",
    "    y = [to_categorical(i, num_classes=len(tags)) for i in y]\n",
    "    \n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И преобразуем обращения и метки тренировочной и проверочной выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = sentences2X(train_sentences[name])\n",
    "X_dev = sentences2X(dev_sentences[name])\n",
    "y_train = sentences2y(train_sentences[name])\n",
    "y_dev = sentences2y(dev_sentences[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим архитектуру нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "\n",
    "layer_input = L.Input(shape=(MAX_LEN,))\n",
    "layer_emb = L.Embedding(input_dim=len(words), output_dim=MAX_LEN, input_length=MAX_LEN)(layer_input)\n",
    "layer_drop = L.Dropout(0.1)(layer_emb)\n",
    "layer_lstm = L.RNN(L.SimpleRNNCell(units=100), return_sequences=True)(layer_drop)\n",
    "layer_output = L.TimeDistributed(L.Dense(len(tags), activation=\"softmax\"))(layer_lstm)\n",
    "model = Model(layer_input, layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Напишем метрики $Precision$ и $Recall$, которые будем использовать во время обучения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $begin\\_recall$ - $Recall$ для метки $н$\n",
    "- $continuous\\_recall$ - $Recall$ для метки $п$\n",
    "- $begin\\_precision$ - $Precision$ для метки $н$\n",
    "- $continuous\\_precision$ - $Precision$ для метки $п$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPS=1e-10\n",
    "def begin_recall(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 1] * y_pred[::, ::, 1]) / (tf.reduce_sum(y_true[::, ::, 1]) + EPS)\n",
    "def continuous_recall(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 2] * y_pred[::, ::, 2]) / (tf.reduce_sum(y_true[::, ::, 2]) + EPS)\n",
    "def begin_precision(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 1] * y_pred[::, ::, 1]) / (tf.reduce_sum(y_pred[::, ::, 1]) + EPS)\n",
    "def continuous_precision(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 2] * y_pred[::, ::, 2]) / (tf.reduce_sum(y_pred[::, ::, 2]) + EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[begin_recall, continuous_recall, begin_precision, continuous_precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И обучим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, np.array(y_train), \n",
    "          batch_size=16, \n",
    "          epochs=5,\n",
    "          validation_data = (X_dev, np.array(y_dev)),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Реализуйте собственную архитектуру рекуррентной нейронной сети и попытайтесь превзойти качество простой модели. Рекомендации к реализации:\n",
    "- Попробуйте варьировать размерность вектора активации сети\n",
    "- Вместо $RNN$ ячейки используйте ячейки $LSTM$ или $BiLSTM$ ($L.LSTM$, $L.Bidirectional(L.LSTM)$)\n",
    "- Попробуйте добавить несколько полносвязных слоев к активации с каждого слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте вашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Начало кода\n",
    "\n",
    "\n",
    "#Конец кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируйте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[begin_recall, continuous_recall, begin_precision, continuous_precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И обучите:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, np.array(y_train), \n",
    "          batch_size=16, \n",
    "          epochs=5,\n",
    "          validation_data = (X_dev, np.array(y_dev)),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert history.history['val_begin_recall'][-1] > 0.62 and history.history['val_continuous_recall'][-1] > 0.75\n",
    "print(\"Результат простой модели превзойден!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
